XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX 
Nodelist:=  gwn03
Number of nodes:=  1
Ntasks per node:=  1
XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX 
NODELIST=gwn03
MASTER_ADDR=gwn03
Starting python script
Using python from /d/hpc/home/ac8694/env/bin/python
Using torch from /d/hpc/home/ac8694/env/lib64/python3.11/site-packages/torch/__init__.py
Using torch cuda from 12.1
Using nccl from (2, 19, 3)
CUDA_HOME=/cvmfs/sling.si/modules/el7/software/CUDA/12.1.1
World size: 2
{'world_size': 2, 'train_type': 'custom_qlora', 'llama_pro_path': None, 'batch_size': 8, 'context_length': 512, 'gradient_accumulation_steps': 1, 'num_epochs': 1, 'dataset': 'dummy', 'dataset_samples': 512, 'sharding_strategy': 'full_shard', 'use_gradient_checkpointing': 1, 'reentrant_checkpointing': False, 'use_cpu_offload': 0, 'use_activation_cpu_offload': 1, 'low_memory': True, 'no_sync': False, 'precision': 'bf16', 'model_name': 'meta-llama/Llama-2-7b-hf', 'save_model': False, 'output_dir': 'output', 'lora_rank': 64, 'lora_alpha': 16, 'lora_dropout': 0.1, 'lora_target_modules': 'all', 'verbose': 1, 'lr': 1e-05, 'apply_gradient_clipping': False, 'grad_norm': 0.3, 'wd': 0.1, 'profile_memory': False, 'optimizer': 'adamw', 'lr_scheduler': 'constant', 'loading_workers': -1, 'log_to': 'stdout', 'master_addr': 'gwn03', 'master_port': '12340', 'seed': 42, 'project_name': 'fsdp_qlora', 'name': None, 'group': None, 'entity': None}
Creating model 1
Creating model 0
Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Downloading shards:  50%|█████     | 1/2 [00:26<00:26, 26.25s/it]Downloading shards:  50%|█████     | 1/2 [00:26<00:26, 26.26s/it]Downloading shards: 100%|██████████| 2/2 [00:35<00:00, 16.47s/it]Downloading shards: 100%|██████████| 2/2 [00:35<00:00, 17.93s/it]
Downloading shards: 100%|██████████| 2/2 [00:35<00:00, 16.47s/it]Downloading shards: 100%|██████████| 2/2 [00:35<00:00, 17.94s/it]
Loading model 0
Total model params: 6738415616
Using n_workers: 32 for loading
Loading model 1
Loading & Quantizing Model Shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading & Quantizing Model Shards:  50%|█████     | 1/2 [02:22<02:22, 142.56s/it]Loading & Quantizing Model Shards: 100%|██████████| 2/2 [02:27<00:00, 61.54s/it] Loading & Quantizing Model Shards: 100%|██████████| 2/2 [02:27<00:00, 73.69s/it]
Loaded model weights in 147.384 seconds
Rank 0: Model created: 0.104 GiB
Using LORA 0
Trainable LORA layer model.layers.0.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.0.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.0.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.0.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.0.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.0.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.0.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.0.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.0.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.0.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.0.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.0.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.1.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.1.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.1.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.1.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.1.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.1.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.1.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.1.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.1.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.1.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.1.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.1.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.2.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.2.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.2.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.2.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.2.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.2.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.2.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.2.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.2.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.2.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.2.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.2.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.3.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.3.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.3.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.3.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.3.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.3.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.3.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.3.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.3.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.3.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.3.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.3.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.4.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.4.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.4.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.4.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.4.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.4.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.4.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.4.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.4.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.4.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.4.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.4.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.5.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.5.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.5.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.5.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.5.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.5.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.5.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.5.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.5.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.5.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.5.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.5.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.6.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.6.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.6.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.6.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.6.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.6.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.6.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.6.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.6.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.6.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.6.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.6.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.7.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.7.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.7.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.7.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.7.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.7.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.7.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.7.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.7.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.7.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.7.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.7.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.8.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.8.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.8.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.8.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.8.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.8.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.8.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.8.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.8.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.8.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.8.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.8.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.9.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.9.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.9.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.9.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.9.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.9.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.9.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.9.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.9.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.9.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.9.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.9.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.10.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.10.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.10.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.10.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.10.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.10.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.10.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.10.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.10.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.10.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.10.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.10.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.11.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.11.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.11.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.11.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.11.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.11.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.11.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.11.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.11.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.11.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.11.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.11.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.12.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.12.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.12.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.12.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.12.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.12.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.12.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.12.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.12.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.12.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.12.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.12.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.13.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.13.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.13.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.13.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.13.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.13.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.13.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.13.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.13.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.13.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.13.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.13.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.14.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.14.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.14.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.14.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.14.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.14.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.14.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.14.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.14.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.14.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.14.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.14.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.15.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.15.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.15.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.15.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.15.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.15.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.15.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.15.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.15.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.15.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.15.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.15.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.16.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.16.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.16.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.16.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.16.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.16.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.16.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.16.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.16.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.16.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.16.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.16.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.17.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.17.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.17.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.17.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.17.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.17.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.17.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.17.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.17.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.17.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.17.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.17.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.18.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.18.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.18.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.18.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.18.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.18.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.18.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.18.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.18.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.18.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.18.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.18.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.19.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.19.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.19.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.19.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.19.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.19.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.19.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.19.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.19.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.19.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.19.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.19.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.20.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.20.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.20.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.20.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.20.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.20.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.20.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.20.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.20.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.20.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.20.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.20.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.21.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.21.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.21.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.21.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.21.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.21.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.21.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.21.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.21.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.21.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.21.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.21.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.22.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.22.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.22.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.22.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.22.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.22.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.22.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.22.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.22.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.22.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.22.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.22.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.23.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.23.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.23.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.23.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.23.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.23.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.23.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.23.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.23.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.23.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.23.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.23.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.24.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.24.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.24.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.24.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.24.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.24.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.24.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.24.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.24.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.24.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.24.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.24.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.25.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.25.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.25.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.25.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.25.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.25.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.25.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.25.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.25.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.25.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.25.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.25.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.26.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.26.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.26.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.26.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.26.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.26.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.26.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.26.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.26.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.26.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.26.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.26.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.27.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.27.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.27.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.27.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.27.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.27.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.27.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.27.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.27.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.27.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.27.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.27.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.28.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.28.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.28.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.28.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.28.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.28.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.28.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.28.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.28.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.28.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.28.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.28.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.29.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.29.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.29.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.29.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.29.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.29.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer Rank 1: Model created: 0.105 GiB
Using LORA 1
Trainable LORA layer model.layers.0.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.0.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.0.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.0.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.0.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.0.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.0.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.0.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.0.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.0.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.0.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.0.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.1.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.1.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.1.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.1.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.1.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.1.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.1.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.1.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.1.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.1.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.1.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.1.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.2.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.2.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.2.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.2.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.2.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.2.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.2.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.2.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.2.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.2.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.2.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.2.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.3.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.3.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.3.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.3.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.3.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.3.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.3.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.3.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.3.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.3.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.3.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.3.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.4.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.4.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.4.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.4.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.4.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.4.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.4.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.4.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.4.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.4.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.4.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.4.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.5.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.5.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.5.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.5.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.5.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.5.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.5.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.5.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.5.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.5.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.5.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.5.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.6.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.6.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.6.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.6.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.6.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.6.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.6.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.6.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.6.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.6.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.6.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.6.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.7.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.7.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.7.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.7.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.7.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.7.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.7.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.7.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.7.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.7.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.7.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.7.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.8.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.8.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.8.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.8.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.8.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.8.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.8.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.8.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.8.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.8.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.8.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.8.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.9.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.9.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.9.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.9.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.9.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.9.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.9.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.9.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.9.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.9.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.9.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.9.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.10.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.10.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.10.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.10.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.10.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.10.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.10.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.10.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.10.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.10.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.10.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.10.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.11.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.11.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.11.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.11.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.11.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.11.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.11.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.11.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.11.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.11.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.11.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.11.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.12.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.12.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.12.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.12.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.12.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.12.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.12.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.12.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.12.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.12.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.12.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.12.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.13.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.13.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.13.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.13.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.13.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.13.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.13.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.13.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.13.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.13.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.13.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.13.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.14.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.14.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.14.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.14.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.14.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.14.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.14.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.14.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.14.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.14.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.14.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.14.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.15.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.15.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.15.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.15.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.15.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.15.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.15.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.15.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.15.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.15.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.15.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.15.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.16.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.16.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.16.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.16.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.16.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.16.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.16.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.16.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.16.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.16.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.16.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.16.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.17.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.17.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.17.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.17.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.17.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.17.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.17.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.17.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.17.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.17.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.17.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.17.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.18.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.18.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.18.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.18.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.18.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.18.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.18.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.18.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.18.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.18.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.18.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.18.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.19.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.19.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.19.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.19.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.19.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.19.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.19.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.19.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.19.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.19.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.19.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.19.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.20.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.20.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.20.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.20.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.20.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.20.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.20.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.20.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.20.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.20.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.20.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.20.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.21.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.21.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.21.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.21.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.21.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.21.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.21.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.21.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.21.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.21.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.21.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.21.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.22.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.22.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.22.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.22.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.22.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.22.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.22.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.22.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.22.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.22.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.22.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.22.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.23.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.23.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.23.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.23.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.23.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.23.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.23.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.23.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.23.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.23.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.23.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.23.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.24.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.24.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.24.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.24.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.24.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.24.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.24.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.24.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.24.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.24.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.24.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.24.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.25.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.25.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.25.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.25.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.25.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.25.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.25.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.25.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.25.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.25.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.25.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.25.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.26.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.26.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.26.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.26.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.26.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.26.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.26.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.26.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.26.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.26.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.26.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.26.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.27.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.27.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.27.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.27.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.27.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.27.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.27.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.27.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.27.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.27.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.27.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.27.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.28.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.28.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.28.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.28.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.28.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.28.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.28.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.28.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.28.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.28.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.28.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.28.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.29.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.29.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.29.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.29.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.29.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.29.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.29.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.29.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.29.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.29.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.29.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.29.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.29.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.30.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.30.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.30.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.30.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.30.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.30.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.30.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.30.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.30.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.30.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.30.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.30.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.31.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.31.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.31.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.31.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.31.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.31.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.31.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.31.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.31.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.31.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.31.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.31.mlp.down_proj.lora_AB.1.weight
Rank 0: LoRA layers added: 0.104 GiB
Wrapping model w/ FSDP 0
Rank 0: Wrapped model: 3.953 GiB
Applying activation checkpointing 0
Applying activation offloading 0
Config:
LlamaConfig {
  "_name_or_path": "meta-llama/Llama-2-7b-hf",
  "architectures": [
    "LlamaForCausalLM"
  ],
  "attention_bias": false,
  "attention_dropout": 0.0,
  "bos_token_id": 1,
  "eos_token_id": 2,
  "hidden_act": "silu",
  "hidden_size": 4096,
  "initializer_range": 0.02,
  "intermediate_size": 11008,
  "max_position_embeddings": 4096,
  "model_type": "llama",
  "num_attention_heads": 32,
  "num_hidden_layers": 32,
  "num_key_value_heads": 32,
  "pretraining_tp": 1,
  "rms_norm_eps": 1e-05,
  "rope_scaling": null,
  "rope_theta": 10000.0,
  "tie_word_embeddings": false,
  "torch_dtype": "float16",
  "transformers_version": "4.40.1",
  "use_cache": false,
  "vocab_size": 32000
}

Model:
OffloadWrapper(
  (_checkpoint_wrapped_module): FullyShardedDataParallel(
    (_fsdp_wrapped_module): LlamaForCausalLM(
      (model): LlamaModel(
        (embed_tokens): Embedding(32000, 4096)
        (layers): ModuleList(
          (0-31): 32 x FullyShardedDataParallel(
            (_fsdp_wrapped_module): CheckpointWrapper(
              (_checkpoint_wrapped_module): LlamaDecoderLayer(
                (self_attn): FullyShardedDataParallel(
                  (_fsdp_wrapped_module): LlamaSdpaAttention(
                    (q_proj): LORA(
                      (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)
                      (lora_AB): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): Sequential(
                          (0): Linear(in_features=4096, out_features=64, bias=False)
                          (1): Linear(in_features=64, out_features=4096, bias=False)
                        )
                      )
                      (lora_dropout): Dropout(p=0.1, inplace=False)
                    )
                    (k_proj): LORA(
                      (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)
                      (lora_AB): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): Sequential(
                          (0): Linear(in_features=4096, out_features=64, bias=False)
                          (1): Linear(in_features=64, out_features=4096, bias=False)
                        )
                      )
                      (lora_dropout): Dropout(p=0.1, inplace=False)
                    )
                    (v_proj): LORA(
                      (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)
                      (lora_AB): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): Sequential(
                          (0): Linear(in_features=4096, out_features=64, bias=False)
                          (1): Linear(in_features=64, out_features=4096, bias=False)
                        )
                      )
                      (lora_dropout): Dropout(p=0.1, inplace=False)
                    )
                    (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)
                    (rotary_emb): LlamaRotaryEmbedding()
                  )
                )
                (mlp): FullyShardedDataParallel(
                  (_fsdp_wrapped_module): LlamaMLP(
                    (gate_proj): LORA(
                      (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)
                      (lora_AB): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): Sequential(
                          (0): Linear(in_features=4096, out_features=64, bias=False)
                          (1): Linear(in_features=64, out_features=11008, bias=False)
                        )
                      )
                      (lora_dropout): Dropout(p=0.1, inplace=False)
                    )
                    (up_proj): LORA(
                      (base_layer): Linear4bit(in_features=4096, out_features=11008, bias=False)
                      (lora_AB): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): Sequential(
                          (0): Linear(in_features=4096, out_features=64, bias=False)
                          (1): Linear(in_features=64, out_features=11008, bias=False)
                        )
                      )
                      (lora_dropout): Dropout(p=0.1, inplace=False)
                    )
                    (down_proj): LORA(
                      (base_layer): Linear4bit(in_features=11008, out_features=4096, bias=False)
                      (lora_AB): FullyShardedDataParallel(
                        (_fsdp_wrapped_module): Sequential(
                          (0): Linear(in_features=11008, out_features=64, bias=False)
                          (1): Linear(in_features=64, out_features=4096, bias=False)
                        )
                      )
                      (lora_dropout): Dropout(p=0.1, inplace=False)
                    )
                    (act_fn): SiLU()
                  )
                )
                (input_layernorm): LlamaRMSNorm()
                (post_attention_layernorm): LlamaRMSNorm()
              )
            )
          )
        )
        (norm): LlamaRMSNorm()
      )
      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)
    )
  )
)
Starting training
Optimizer params:
Shape: torch.Size([131074048]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([4096]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([8388608]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([262144]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([16908288]), Requires Grad: False, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Shape: torch.Size([483328]), Requires Grad: True, Dtype: torch.bfloat16
Total Training Steps: 32
  0%|          | 0/32 [00:00<?, ?it/s]Epoch 0, Loss 0.000:   0%|          | 0/32 [00:00<?, ?it/s]Epoch 0, Loss 0.000:   3%|▎         | 1/32 [00:05<03:01,  5.85s/it]Epoch 0, Loss 0.098, LR 1.00e-05:   3%|▎         | 1/32 [00:05<03:01,  5.85s/it]Epoch 0, Loss 0.098, LR 1.00e-05:   6%|▋         | 2/32 [00:09<02:08,  4.27s/it]Epoch 0, Loss 0.098, LR 1.00e-05:   6%|▋         | 2/32 [00:09<02:08,  4.27s/it]Epoch 0, Loss 0.098, LR 1.00e-05:   9%|▉         | 3/32 [00:12<01:49,  3.78s/it]Epoch 0, Loss 0.098, LR 1.00e-05:   9%|▉         | 3/32 [00:12<01:49,  3.78s/it]Epoch 0, Loss 0.098, LR 1.00e-05:  12%|█▎        | 4/32 [00:15<01:39,  3.54s/it]Epoch 0, Loss 0.097, LR 1.00e-05:  12%|█▎        | 4/32 [00:15<01:39,  3.54s/it]Epoch 0, Loss 0.097, LR 1.00e-05:  16%|█▌        | 5/32 [00:18<01:31,  3.41s/it]Epoch 0, Loss 0.097, LR 1.00e-05:  16%|█▌        | 5/32 [00:18<01:31,  3.41s/it]Epoch 0, Loss 0.097, LR 1.00e-05:  19%|█▉        | 6/32 [00:21<01:26,  3.33s/it]Epoch 0, Loss 0.097, LR 1.00e-05:  19%|█▉        | 6/32 [00:21<01:26,  3.33s/it]Epoch 0, Loss 0.097, LR 1.00e-05:  22%|██▏       | 7/32 [00:24<01:21,  3.28s/it]Epoch 0, Loss 0.096, LR 1.00e-05:  22%|██▏       | 7/32 [00:24<01:21,  3.28s/it]Epoch 0, Loss 0.096, LR 1.00e-05:  25%|██▌       | 8/32 [00:28<01:17,  3.24s/it]Epoch 0, Loss 0.095, LR 1.00e-05:  25%|██▌       | 8/32 [00:28<01:17,  3.24s/it]Epoch 0, Loss 0.095, LR 1.00e-05:  28%|██▊       | 9/32 [00:31<01:15,  3.27s/it]Epoch 0, Loss 0.095, LR 1.00e-05:  28%|██▊       | 9/32 [00:31<01:15,  3.27s/it]Epoch 0, Loss 0.095, LR 1.00e-05:  31%|███▏      | 10/32 [00:34<01:11,  3.25s/it]Epoch 0, Loss 0.094, LR 1.00e-05:  31%|███▏      | 10/32 [00:34<01:11,  3.25s/it]Epoch 0, Loss 0.094, LR 1.00e-05:  34%|███▍      | 11/32 [00:37<01:07,  3.22s/it]Epoch 0, Loss 0.094, LR 1.00e-05:  34%|███▍      | 11/32 [00:37<01:07,  3.22s/it]Epoch 0, Loss 0.094, LR 1.00e-05:  38%|███▊      | 12/32 [00:40<01:04,  3.21s/it]Epoch 0, Loss 0.093, LR 1.00e-05:  38%|███▊      | 12/32 [00:40<01:04,  3.21s/it]Epoch 0, Loss 0.093, LR 1.00e-05:  41%|████      | 13/32 [00:44<01:00,  3.20s/it]Epoch 0, Loss 0.092, LR 1.00e-05:  41%|████      | 13/32 [00:44<01:00,  3.20s/it]Epoch 0, Loss 0.092, LR 1.00e-05:  44%|████▍     | 14/32 [00:47<00:57,  3.19s/it]Epoch 0, Loss 0.092, LR 1.00e-05:  44%|████▍     | 14/32 [00:47<00:57,  3.19s/it]Epoch 0, Loss 0.092, LR 1.00e-05:  47%|████▋     | 15/32 [00:50<00:54,  3.19s/it]Epoch 0, Loss 0.091, LR 1.00e-05:  47%|████▋     | 15/32 [00:50<00:54,  3.19s/it]Epoch 0, Loss 0.091, LR 1.00e-05:  50%|█████     | 16/32 [00:53<00:50,  3.18s/it]Epoch 0, Loss 0.090, LR 1.00e-05:  50%|█████     | 16/32 [00:53<00:50,  3.18s/it]Epoch 0, Loss 0.090, LR 1.00e-05:  53%|█████▎    | 17/32 [00:56<00:48,  3.23s/it]Epoch 0, Loss 0.090, LR 1.00e-05:  53%|█████▎    | 17/32 [00:56<00:48,  3.23s/it]Epoch 0, Loss 0.090, LR 1.00e-05:  56%|█████▋    | 18/32 [01:00<00:44,  3.21s/it]Epoch 0, Loss 0.089, LR 1.00e-05:  56%|█████▋    | 18/32 [01:00<00:44,  3.21s/it]Epoch 0, Loss 0.089, LR 1.00e-05:  59%|█████▉    | 19/32 [01:03<00:41,  3.20s/it]Epoch 0, Loss 0.088, LR 1.00e-05:  59%|█████▉    | 19/32 [01:03<00:41,  3.20s/it]Epoch 0, Loss 0.088, LR 1.00e-05:  62%|██████▎   | 20/32 [01:06<00:38,  3.19s/it]Epoch 0, Loss 0.087, LR 1.00e-05:  62%|██████▎   | 20/32 [01:06<00:38,  3.19s/it]Epoch 0, Loss 0.087, LR 1.00e-05:  66%|██████▌   | 21/32 [01:09<00:35,  3.18s/it]Epoch 0, Loss 0.087, LR 1.00e-05:  66%|██████▌   | 21/32 [01:09<00:35,  3.18s/it]Epoch 0, Loss 0.087, LR 1.00e-05:  69%|██████▉   | 22/32 [01:12<00:31,  3.18s/it]Epoch 0, Loss 0.086, LR 1.00e-05:  69%|██████▉   | 22/32 [01:12<00:31,  3.18s/it]Epoch 0, Loss 0.086, LR 1.00e-05:  72%|███████▏  | 23/32 [01:16<00:28,  3.18s/it]Epoch 0, Loss 0.086, LR 1.00e-05:  72%|███████▏  | 23/32 [01:16<00:28,  3.18s/it]Epoch 0, Loss 0.086, LR 1.00e-05:  75%|███████▌  | 24/32 [01:19<00:25,  3.18s/it]Epoch 0, Loss 0.085, LR 1.00e-05:  75%|███████▌  | 24/32 [01:19<00:25,  3.18s/it]Epoch 0, Loss 0.085, LR 1.00e-05:  78%|███████▊  | 25/32 [01:22<00:22,  3.18s/it]Epoch 0, Loss 0.084, LR 1.00e-05:  78%|███████▊  | 25/32 [01:22<00:22,  3.18s/it]Epoch 0, Loss 0.084, LR 1.00e-05:  81%|████████▏ | 26/32 [01:25<00:19,  3.23s/it]Epoch 0, Loss 0.084, LR 1.00e-05:  81%|████████▏ | 26/32 [01:25<00:19,  3.23s/it]Epoch 0, Loss 0.084, LR 1.00e-05:  84%|████████▍ | 27/32 [01:28<00:16,  3.21s/it]Epoch 0, Loss 0.083, LR 1.00e-05:  84%|████████▍ | 27/32 [01:28<00:16,  3.21s/it]Epoch 0, Loss 0.083, LR 1.00e-05:  88%|████████▊ | 28/32 [01:32<00:12,  3.20s/it]Epomodel.layers.29.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.29.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.29.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.29.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.29.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.30.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.30.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.30.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.30.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.30.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.30.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.30.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.30.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.30.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.30.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.30.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.30.mlp.down_proj.lora_AB.1.weight
Trainable LORA layer model.layers.31.self_attn.q_proj.lora_AB.0.weight
Trainable LORA layer model.layers.31.self_attn.q_proj.lora_AB.1.weight
Trainable LORA layer model.layers.31.self_attn.k_proj.lora_AB.0.weight
Trainable LORA layer model.layers.31.self_attn.k_proj.lora_AB.1.weight
Trainable LORA layer model.layers.31.self_attn.v_proj.lora_AB.0.weight
Trainable LORA layer model.layers.31.self_attn.v_proj.lora_AB.1.weight
Trainable LORA layer model.layers.31.mlp.gate_proj.lora_AB.0.weight
Trainable LORA layer model.layers.31.mlp.gate_proj.lora_AB.1.weight
Trainable LORA layer model.layers.31.mlp.up_proj.lora_AB.0.weight
Trainable LORA layer model.layers.31.mlp.up_proj.lora_AB.1.weight
Trainable LORA layer model.layers.31.mlp.down_proj.lora_AB.0.weight
Trainable LORA layer model.layers.31.mlp.down_proj.lora_AB.1.weight
Rank 1: LoRA layers added: 0.105 GiB
Wrapping model w/ FSDP 1
Rank 1: Wrapped model: 5.760 GiB
Applying activation checkpointing 1
Applying activation offloading 1
Rank 1: Before forward: 5.76 GiB
Rank 1: After forward: 11.17 GiB
Rank 1: After backward: 12.22 GiB
Rank 1: Peak allocated memory: 10.54 GiB
Rank 1: Peak reserved memory:  12.22 GiB
ch 0, Loss 0.082, LR 1.00e-05:  88%|████████▊ | 28/32 [01:32<00:12,  3.20s/it]Epoch 0, Loss 0.082, LR 1.00e-05:  91%|█████████ | 29/32 [01:35<00:09,  3.19s/it]Epoch 0, Loss 0.082, LR 1.00e-05:  91%|█████████ | 29/32 [01:35<00:09,  3.19s/it]Epoch 0, Loss 0.082, LR 1.00e-05:  94%|█████████▍| 30/32 [01:38<00:06,  3.19s/it]Epoch 0, Loss 0.081, LR 1.00e-05:  94%|█████████▍| 30/32 [01:38<00:06,  3.19s/it]Epoch 0, Loss 0.081, LR 1.00e-05:  97%|█████████▋| 31/32 [01:41<00:03,  3.18s/it]Epoch 0, Loss 0.080, LR 1.00e-05:  97%|█████████▋| 31/32 [01:41<00:03,  3.18s/it]Epoch 0, Loss 0.080, LR 1.00e-05: 100%|██████████| 32/32 [01:44<00:00,  3.18s/it]Epoch 0, Loss 0.080, LR 1.00e-05: 100%|██████████| 32/32 [01:44<00:00,  3.18s/it]Epoch 0, Loss 0.080, LR 1.00e-05: 100%|██████████| 32/32 [01:44<00:00,  3.28s/it]
Finished training 0
CUDA event elapsed time: 104.7463984375 sec
time_taken: 104.7463984375
Rank 0: Before forward: 3.95 GiB
Rank 0: After forward: 12.13 GiB
Rank 0: After backward: 13.21 GiB
Rank 0: Peak allocated memory: 10.78 GiB
Rank 0: Peak reserved memory:  13.21 GiB
